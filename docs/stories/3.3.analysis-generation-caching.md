# Story 3.3: Analysis Generation & Caching Logic

## Status
Draft

## Story
**As a** developer,
**I want** an analysis engine that generates and caches LLM insights,
**so that** redundant API calls are avoided and results are stored.

## Acceptance Criteria

1. Analysis engine function accepts: comparison type, brand(s), plan data
2. Engine checks `analyses` table for existing analysis matching criteria
3. If cached analysis found (same comparison, same plan data), return cached result
4. If no cache hit, call Gemini API with appropriate prompt + plan data
5. Parse and validate LLM response
6. Store analysis result in `analyses` table with metadata
7. Return analysis to caller
8. Error handling for API failures, timeouts, invalid responses
9. Unit tests with mocked Gemini API responses

## Tasks / Subtasks

- [ ] Create analysis engine function (AC: 1)
  - [ ] Create `src/lib/llm/analysis.ts`
  - [ ] Define function signature (comparison type, brands, plan data)
  - [ ] Set up function structure
- [ ] Implement cache checking (AC: 2, 3)
  - [ ] Query `analyses` table for existing analysis
  - [ ] Match on comparison type and brands
  - [ ] Match on plan data (hash or compare plan IDs)
  - [ ] Return cached result if found
- [ ] Implement analysis generation (AC: 4)
  - [ ] Load appropriate prompt template
  - [ ] Format plan data for prompt
  - [ ] Call Gemini API with prompt + data
  - [ ] Handle API response
- [ ] Implement response parsing and validation (AC: 5)
  - [ ] Parse LLM response
  - [ ] Use validation utility from Story 3.2
  - [ ] Handle invalid responses
- [ ] Store analysis in database (AC: 6)
  - [ ] Store in `analyses` table
  - [ ] Include metadata (comparison_type, brands, plan_ids, created_at)
  - [ ] Store analysis_result as JSONB
- [ ] Return analysis result (AC: 7)
  - [ ] Return structured analysis data
  - [ ] Handle both cached and new analyses
- [ ] Implement error handling (AC: 8)
  - [ ] Handle API failures
  - [ ] Handle timeouts
  - [ ] Handle invalid responses
  - [ ] Provide meaningful error messages
- [ ] Write unit tests (AC: 9)
  - [ ] Create `tests/unit/llm/analysis.test.ts`
  - [ ] Mock Gemini API responses
  - [ ] Test cache checking logic
  - [ ] Test analysis generation
  - [ ] Test error handling

## Dev Notes

### Source Tree
- Analysis engine: `src/lib/llm/analysis.ts`
- Gemini client: `src/lib/llm/gemini.ts` (from Story 3.1)
- Prompts: `src/lib/llm/prompts/` (from Story 3.2)
- Validation: `src/lib/llm/validation.ts` (from Story 3.2)
- Database: `src/lib/db/` (from Story 1.2, 2.1)

### Technical Stack
- Google Gemini 2.5 Pro API
- PostgreSQL for caching
- JSONB for flexible analysis storage

### Testing
- Test file location: `tests/unit/llm/analysis.test.ts`
- Test framework: Jest
- Mock Gemini API responses
- Test caching logic
- Test error handling

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-XX | 1.0 | Story extracted from PRD | Architect |

## Dev Agent Record

### Agent Model Used
_To be populated by Dev Agent_

### Debug Log References
_To be populated by Dev Agent_

### Completion Notes List
_To be populated by Dev Agent_

### File List
_To be populated by Dev Agent_

## QA Results
_To be populated by QA Agent_

