# Story 2.5: Data Normalization Before Storage

## Status
Draft

## Story
**As a** developer,
**I want** a normalization layer that processes raw scraped data before database insertion,
**so that** plan data from different sources is stored in a consistent format for analysis.

## Dependencies
- Story 2.1: Database Schema Design (Done)
- Story 2.2: Data Collectors - Telcos (Must complete first - provides real data formats)
- Story 2.3: Uswitch API Integration (Must complete first - provides API data formats)
- Story 2.4: Unified Data Collection (Must complete first - provides orchestration context)

**Note:** This story must be implemented AFTER Stories 2.2-2.4 to understand actual data format variations from all sources.

## Acceptance Criteria

1. Normalization function processes raw scraped data from all sources (7 telcos + Uswitch API)
2. Normalizes data allowance formats based on ACTUAL formats discovered:
   - Examples: "Unlimited", "100GB", "100 GB", "100G" → standardized format
3. Normalizes pricing formats based on ACTUAL formats discovered:
   - Examples: "£10/mo", "10 GBP per month", "£10 a month", "10.00" → standardized format
4. Normalizes contract terms based on ACTUAL formats discovered:
   - Examples: "12 months", "12-month", "1 year", "12m" → standardized format
5. Generates `plan_key` field for historical tracking:
   - Format: `{source}-{data_allowance}-{contract_term}` (e.g., "O2-10GB-12months")
   - Handles edge cases (Unlimited, PAYG, variable terms)
6. Handles multiple input formats from real sources:
   - Scraped HTML text (Playwright collectors)
   - Structured objects (some telco sites)
   - API JSON responses (Smarty, Uswitch)
7. Error handling for malformed data:
   - Gracefully handles null, undefined, missing fields
   - Logs warnings for unexpected formats
   - Continues processing (doesn't fail entire batch)
8. Integration with all collectors:
   - Each collector calls normalization before database insertion
   - Normalized data written to `plans.plan_data` JSONB field
   - `plan_key` populated in `plans.plan_key` field
9. Unit tests covering ACTUAL format variations discovered across all sources
10. Documentation of normalization rules and format mappings per source

## Tasks / Subtasks

**Tasks will be refined after Stories 2.2-2.4 completion when real data formats are known.**

Preliminary task outline:
- [ ] Analyze real data formats from Stories 2.2-2.4 (AC: 1-6)
  - [ ] Collect sample outputs from all 7 telco collectors
  - [ ] Collect sample outputs from Uswitch API
  - [ ] Document format variations per source
  - [ ] Identify normalization patterns
- [ ] Create normalization utility (AC: 1-6)
  - [ ] Create `src/lib/scraping/normalize.ts`
  - [ ] Implement data allowance normalization
  - [ ] Implement pricing normalization
  - [ ] Implement contract term normalization
  - [ ] Implement plan_key generation logic
  - [ ] Handle input format variations (HTML text, objects, JSON)
- [ ] Implement error handling (AC: 7)
  - [ ] Handle null/undefined/missing fields gracefully
  - [ ] Add warning logs for unexpected formats
  - [ ] Ensure processing continues on errors
- [ ] Integrate with collectors (AC: 8)
  - [ ] Update all telco collectors to call normalization
  - [ ] Update Uswitch collector to call normalization
  - [ ] Ensure normalized data written to database
  - [ ] Ensure plan_key populated correctly
- [ ] Write comprehensive tests (AC: 9)
  - [ ] Create `src/lib/scraping/__tests__/normalize.test.ts`
  - [ ] Test all discovered format variations
  - [ ] Test plan_key generation edge cases
  - [ ] Test error handling scenarios
  - [ ] Achieve 80%+ coverage for normalization logic
- [ ] Document normalization rules (AC: 10)
  - [ ] Create normalization mapping documentation
  - [ ] Document per-source format quirks
  - [ ] Add inline code comments explaining rules

## Dev Notes

### Source Tree
- Normalization utility: `src/lib/scraping/normalize.ts`
- Test file: `src/lib/scraping/__tests__/normalize.test.ts`
- Integration points: All collectors in `src/lib/scraping/collectors/`

### Technical Stack
- TypeScript with strict types for normalization functions
- Vitest for testing
- Structured logging for warnings/errors

### Data Flow
```
Collector (raw scrape) → normalize() → Database (plans table)
                              ↓
                      Standardized format:
                      - plan_data: JSONB (normalized)
                      - plan_key: TEXT (generated)
```

### Normalization Philosophy
- **Preserve original data**: Store raw data alongside normalized data for auditing
- **Fail gracefully**: Log warnings but continue processing
- **Source-specific rules**: Document quirks per telco/aggregator
- **plan_key consistency**: Same plan from multiple scrapes gets same key

### Testing Strategy
- Test file location: `src/lib/scraping/__tests__/normalize.test.ts` (co-located)
- Test framework: Vitest (aligned with project standards)
- Test with REAL data samples from all sources
- Coverage target: 80%+ for normalization logic

### plan_key Generation Strategy
Format: `{source}-{data_allowance}-{contract_term}`

Examples:
- O2, 10GB, 12 months → `O2-10GB-12months`
- Vodafone, Unlimited, 24 months → `Vodafone-Unlimited-24months`
- Three, 50GB, 1 month → `Three-50GB-1month`
- Sky, 100GB, PAYG → `Sky-100GB-PAYG`

Edge cases to handle:
- Unlimited data
- Pay-as-you-go (PAYG) plans
- Variable contract terms
- Promotional plans with changing allowances

## Relationship to Story 1.4

**Story 2.5** (this story):
- Focus: Normalization BEFORE database insertion
- Timing: After data collection (2.2-2.4), before refactoring (1.4)
- Scope: Process raw data into consistent format for storage
- Output: Populated `plan_data` JSONB and `plan_key` fields

**Story 1.4** (Data Normalization Utility - Refactoring):
- Focus: Refactor/improve existing normalization based on production experience
- Timing: After Epic 2 complete, before Epic 3
- Scope: Optimize normalization logic, improve error handling, refine plan_key generation
- Output: Enhanced normalization utility with lessons learned

Story 2.5 provides the initial working normalization. Story 1.4 will refine it based on real-world usage.

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-17 | 1.0 | Story created to handle normalization between data collection and storage | PM Agent (John) |

## Dev Agent Record

### Agent Model Used
_To be populated by Dev Agent_

### Implementation Summary
_To be populated by Dev Agent_

### Completion Notes List
_To be populated by Dev Agent_

### File List
_To be populated by Dev Agent_

## QA Results
_To be populated by QA Agent_
