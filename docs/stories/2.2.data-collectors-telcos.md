# Story 2.2: Data Collectors for Remaining Telco Sources

## Status
Draft

## Story
**As a** developer,
**I want** data collectors for all 7 telco sources (O2, Vodafone, Sky, Tesco, Smarty, Three, Giffgaff),
**so that** complete competitive data can be collected.

## Acceptance Criteria

1. Individual collector modules created for each remaining telco (6 new + 1 from POC):
   - **Playwright scrapers**: Vodafone, Sky, Tesco, Three, Giffgaff (+ O2 from POC)
   - **API integration**: Smarty (REST API endpoint)
2. Each collector extracts: pricing, data allowance, contract term, promotional extras
3. Playwright scrapers handle:
   - Cookie consent modals (site-specific selectors)
   - Multiple contract lengths where applicable (e.g., 1/12/24 months)
   - Modal interactions for extended details (e.g., Vodafone tabs)
   - Browser selection (webkit vs chromium based on compatibility)
4. Collected data passes through normalization utility before storage
5. Each collector handles source-specific edge cases and layout variations
6. Retry logic and error handling implemented per collector
7. All collectors write data to `plans` table with proper metadata
8. Unit tests for each collector (mocked page content or API responses)
9. `npm run scrape:telcos` command runs all 7 telco collectors sequentially

## Tasks / Subtasks

- [ ] Create collector modules (AC: 1)
  - [ ] Create `src/lib/scraping/collectors/vodafone.ts`
  - [ ] Create `src/lib/scraping/collectors/sky.ts`
  - [ ] Create `src/lib/scraping/collectors/tesco.ts`
  - [ ] Create `src/lib/scraping/collectors/three.ts`
  - [ ] Create `src/lib/scraping/collectors/giffgaff.ts`
  - [ ] Create `src/lib/scraping/collectors/smarty.ts` (API integration)
  - [ ] Update O2 collector from POC (if needed)
- [ ] Implement Playwright scrapers (AC: 2, 3)
  - [ ] Extract pricing, data allowance, contract term, extras for each
  - [ ] Handle cookie consent modals (site-specific)
  - [ ] Handle multiple contract lengths where applicable
  - [ ] Handle modal interactions (e.g., Vodafone tabs)
  - [ ] Choose appropriate browser (webkit vs chromium)
- [ ] Implement Smarty API integration (AC: 2)
  - [ ] Create REST API client for Smarty
  - [ ] Fetch plan data from API endpoint
  - [ ] Extract required fields
- [ ] Integrate normalization (AC: 4)
  - [ ] Pass all collected data through normalization utility
  - [ ] Verify normalized output
- [ ] Handle edge cases (AC: 5)
  - [ ] Handle source-specific layout variations
  - [ ] Handle missing data gracefully
  - [ ] Document edge cases per source
- [ ] Implement error handling (AC: 6)
  - [ ] Add retry logic to each collector
  - [ ] Handle timeout errors
  - [ ] Handle element not found errors
  - [ ] Add error logging
- [ ] Store data in database (AC: 7)
  - [ ] Write collected data to `plans` table
  - [ ] Include proper metadata (source, scrape_timestamp, plan_id)
  - [ ] Handle database errors
- [ ] Write unit tests (AC: 8)
  - [ ] Create test files for each collector
  - [ ] Mock Playwright page content or API responses
  - [ ] Test data extraction logic
  - [ ] Test error handling
- [ ] Create npm script (AC: 9)
  - [ ] Add `scrape:telcos` script to `package.json`
  - [ ] Implement sequential execution of all 7 collectors
  - [ ] Test script execution

## Dev Notes

### Source Tree
- Collectors: `src/lib/scraping/collectors/{telco}.ts`
- Normalization: `src/lib/scraping/normalize.ts` (from Story 1.4)
- Database: `src/lib/db/` (from Story 1.2, 2.1)

### Technical Stack
- Playwright for browser automation (6 telcos)
- REST API client (fetch) for Smarty
- Normalization utility for data consistency
- PostgreSQL for data storage

### Testing
- Test file location: `tests/integration/scraping/collectors/` (to be created)
- Test framework: Jest with mocked Playwright/API
- Mock network requests to avoid hitting real sites
- Test each collector individually

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-XX | 1.0 | Story extracted from PRD | Architect |

## Dev Agent Record

### Agent Model Used
_To be populated by Dev Agent_

### Debug Log References
_To be populated by Dev Agent_

### Completion Notes List
_To be populated by Dev Agent_

### File List
_To be populated by Dev Agent_

## QA Results
_To be populated by QA Agent_

