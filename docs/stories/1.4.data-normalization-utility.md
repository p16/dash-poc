# Story 1.4: Data Normalization Utility - Refactoring & Enhancement

## Status
Draft

## Story
**As a** developer,
**I want** to refactor and enhance the existing normalization utility based on production experience,
**so that** normalization logic is optimized, maintainable, and handles edge cases discovered in real usage.

**Note:** This story refines the normalization layer initially created in Story 2.5. It focuses on improvements based on actual production data and usage patterns.

## Dependencies
- Story 2.1: Database Schema Design (Done)
- Story 2.2: Data Collectors - Telcos (Must complete first)
- Story 2.3: Uswitch API Integration (Must complete first)
- Story 2.4: Unified Data Collection (Must complete first)
- Story 2.5: Data Normalization Before Storage (Must complete first - provides initial normalization layer)

**Positioning:** This story comes AFTER Epic 2 (Data Collection) is complete, before Epic 3 (LLM Analysis). It's a refactoring/improvement story based on real-world experience.

## Relationship to Story 2.5

**Story 2.5** (Data Normalization Before Storage):
- Created initial normalization layer for immediate use
- Implemented during Epic 2 (after data collection, before storage)
- Focus: Get normalization working with discovered data formats
- Output: Working normalize() function that populates plan_data and plan_key

**Story 1.4** (this story - Refactoring):
- Refines/improves Story 2.5 normalization based on production usage
- Implemented after Epic 2 complete, before Epic 3
- Focus: Optimize performance, improve error handling, enhance plan_key generation
- Output: Enhanced normalization with lessons learned from production data

## Acceptance Criteria

**Note:** These ACs will be refined after Story 2.5 completion based on actual performance and edge cases encountered.

**Note:** These ACs will be refined after Story 2.5 completion based on actual performance and edge cases encountered.

1. Refactor normalization logic for better performance:
   - Optimize data allowance normalization (reduce regex operations)
   - Optimize pricing normalization (cache conversion rates if needed)
   - Improve plan_key generation efficiency
2. Enhance error handling based on production issues discovered:
   - Handle new edge cases found in production data
   - Improve logging for debugging
   - Add retry logic for transient failures (if patterns emerge)
3. Improve plan_key generation based on real-world duplicates:
   - Refine algorithm to reduce collisions
   - Handle promotional plans more accurately
   - Document plan_key generation rules comprehensively
4. Add performance monitoring:
   - Track normalization execution time
   - Identify slow normalization operations
   - Optimize bottlenecks
5. Enhance testing based on production data:
   - Add test cases for edge cases discovered in production
   - Improve test coverage to 90%+
   - Add performance benchmarks
6. Documentation improvements:
   - Update normalization rules based on production experience
   - Add troubleshooting guide for common issues
   - Document performance characteristics

## Tasks / Subtasks

**Tasks will be defined after Story 2.5 completion when production experience is available.**

Preliminary task outline:
- [ ] Analyze Story 2.5 normalization performance in production (AC: 1, 4)
  - [ ] Collect metrics on normalization execution time
  - [ ] Identify performance bottlenecks
  - [ ] Review error logs for patterns
- [ ] Refactor normalization logic (AC: 1)
  - [ ] Optimize data allowance normalization
  - [ ] Optimize pricing normalization
  - [ ] Improve plan_key generation algorithm
  - [ ] Add performance benchmarks
- [ ] Enhance error handling (AC: 2)
  - [ ] Add handling for production edge cases
  - [ ] Improve error logging
  - [ ] Consider retry logic if needed
- [ ] Improve plan_key generation (AC: 3)
  - [ ] Analyze plan_key collisions in production
  - [ ] Refine generation algorithm
  - [ ] Update documentation
- [ ] Add monitoring (AC: 4)
  - [ ] Instrument normalization with timing metrics
  - [ ] Add structured logging for performance
  - [ ] Create performance dashboard/alerts
- [ ] Enhance testing (AC: 5)
  - [ ] Add test cases for production edge cases
  - [ ] Improve coverage to 90%+
  - [ ] Add performance benchmarks to test suite
- [ ] Update documentation (AC: 6)
  - [ ] Document lessons learned
  - [ ] Create troubleshooting guide
  - [ ] Update normalization rules
  - [ ] Review O2 scraper output formats
  - [ ] Review Sky scraper output formats
  - [ ] Review Vodafone scraper output formats
  - [ ] Review Smarty API response formats
  - [ ] Document all format variations discovered
- [ ] Create normalization utility file (AC: 1, 2, 3)
  - [ ] Create `src/lib/scraping/normalize.ts`
  - [ ] Implement data normalization functions based on actual formats
  - [ ] Create main normalization orchestration function
- [ ] Write unit tests (AC: 4)
  - [ ] Create `src/lib/scraping/__tests__/normalize.test.ts`
  - [ ] Test ACTUAL data format variations discovered
  - [ ] Achieve 60%+ test coverage
- [ ] Handle edge cases (AC: 5)
  - [ ] Handle null/undefined inputs
  - [ ] Handle malformed inputs
  - [ ] Handle missing fields
  - [ ] Add appropriate error handling (fail fast)
- [ ] Document normalization rules (AC: 6)
  - [ ] Document rules per source type
  - [ ] Document assumptions
  - [ ] Add JSDoc comments to functions

## Dev Notes

**Important:** This story refines the normalization implemented in Story 2.5. Focus is on optimization and enhancement based on production experience.

### Source Tree
- Normalization utility: `src/lib/scraping/normalize.ts` (created in Story 2.5, enhanced here)
- Test file: `src/lib/scraping/__tests__/normalize.test.ts` (co-located)
- Performance monitoring: Added instrumentation to existing functions

### Technical Stack
- TypeScript for type safety
- Performance profiling tools
- Enhanced structured logging
- Support for multiple input formats discovered in Story 2.2

### Testing
- Test file location: `src/lib/scraping/__tests__/normalize.test.ts`
- Test framework: Vitest (aligned with Stories 1.2, 1.3)
- Coverage target: 60%+ for critical business logic
- Test ACTUAL format variations discovered in Story 2.2

### Implementation Approach
1. Complete Story 2.2 first (collect data from all telco sources)
2. Analyze actual data format variations
3. Determine if normalization utility is needed or if inline handling is sufficient
4. If needed, design normalization strategy based on real patterns
5. Implement with fail-fast error handling (no retry logic)

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-XX | 1.0 | Story extracted from PRD | Architect |
| 2025-11-17 | 1.1 | Moved to Draft, repositioned after Story 2.2, updated to be data-driven refactoring story | PM Agent (John) |
| 2025-01-17 | 1.2 | Redefined as refactoring/enhancement story after Story 2.5. Focus changed from initial normalization (now Story 2.5) to optimization and improvement based on production experience | PM Agent (John) |

## Dev Agent Record

### Agent Model Used
_To be populated by Dev Agent_

### Debug Log References
_To be populated by Dev Agent_

### Completion Notes List
_To be populated by Dev Agent_

### File List
_To be populated by Dev Agent_

## QA Results
_To be populated by QA Agent_

