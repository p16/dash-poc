# Story 4.6: Trigger Scrape from Dashboard (Manual/Cron)

## Status
Draft

## Story
**As a** user,
**I want** to see when the last scrape ran and have instructions to manually trigger scraping,
**so that** I can refresh plan data on demand without complex job queue infrastructure.

## Acceptance Criteria

1. Dashboard displays "Last Scrape" timestamp and status
2. "Refresh Data" section shows instructions: "To update plan data, run: npm run scrape:all"
3. Button to copy the command to clipboard for convenience
4. Data freshness indicator (green <24h, yellow 24-48h, red >48h) from Story 4.2
5. After manual scrape completes, user can refresh dashboard to see new data
6. Optional: Link to cron setup documentation for automated scheduling
7. Clean UI with Tailwind CSS styling

**MVP Scope Note:** This story uses manual command execution instead of API-triggered scraping to avoid serverless timeout issues. Scraping runs locally or via cron, not through Next.js API routes.

## Tasks / Subtasks

- [ ] Display last scrape information (AC: 1)
  - [ ] Query: `SELECT MAX(scrape_timestamp) FROM plans`
  - [ ] Display timestamp in user-friendly format
  - [ ] Show status indicator (uses same logic as Story 4.2)
- [ ] Add refresh instructions section (AC: 2)
  - [ ] Create "Refresh Data" card/section
  - [ ] Display instruction text: "To update plan data, run: npm run scrape:all"
  - [ ] Style with Tailwind CSS
- [ ] Add copy-to-clipboard button (AC: 3)
  - [ ] Add button next to command text
  - [ ] Implement clipboard copy functionality
  - [ ] Show success message after copy
- [ ] Implement data freshness indicator (AC: 4)
  - [ ] Reuse freshness logic from Story 4.2
  - [ ] Display green (<24h), yellow (24-48h), red (>48h)
  - [ ] Calculate hours since last scrape
- [ ] Add manual refresh note (AC: 5)
  - [ ] Display message: "After running scrape command, refresh this page to see updated data"
  - [ ] Add manual refresh button (browser refresh)
- [ ] Add cron documentation link (AC: 6)
  - [ ] Create simple cron setup doc (optional)
  - [ ] Example: `0 2 * * * cd /path/to/project && npm run scrape:all`
  - [ ] Link to documentation from dashboard
- [ ] Style UI (AC: 7)
  - [ ] Use Tailwind CSS for clean design
  - [ ] Make instructions prominent but not intrusive
  - [ ] Ensure responsive layout

## Dev Notes

### Source Tree
- Dashboard page: `src/app/dashboard/page.tsx` (from Story 4.2)
- Scraping script: `src/scripts/scrape.ts` (from Story 2.4)
- Database schema: Story 2.1 (`plans` table)
- Refresh instructions component: `src/components/dashboard/RefreshInstructions.tsx` (to be created)

### Technical Stack
- React components for UI display
- Clipboard API for copy-to-clipboard functionality
- Database queries for scrape timestamp
- Manual command execution (no API endpoint needed)
- Optional: Cron setup documentation

### MVP Implementation Note
This story avoids creating a `/api/scrape` endpoint to sidestep serverless timeout issues (scraping takes 10+ minutes). Instead, users run scraping manually via `npm run scrape:all` or set up a cron job for automated scheduling. This is simpler, more reliable, and avoids job queue infrastructure for MVP.

### Future Enhancement
Post-MVP, consider adding job queue (BullMQ, Inngest) for in-dashboard scrape triggering with progress updates.

### Testing
- Test file location: `tests/unit/components/dashboard/RefreshInstructions.test.tsx` (to be created)
- Test framework: Jest + React Testing Library
- Test copy-to-clipboard, data display, freshness indicator

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-XX | 1.0 | Story extracted from PRD | Architect |

## Dev Agent Record

### Agent Model Used
_To be populated by Dev Agent_

### Debug Log References
_To be populated by Dev Agent_

### Completion Notes List
_To be populated by Dev Agent_

### File List
_To be populated by Dev Agent_

## QA Results
_To be populated by QA Agent_

