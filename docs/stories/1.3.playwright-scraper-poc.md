# Story 1.3: Playwright Scraper POC for Single Telco Source

## Status
Ready for Review

## Story
**As a** developer,
**I want** to build a proof-of-concept scraper for one telco website using Playwright,
**so that** I can validate the scraping approach works for JavaScript-heavy sites.

## Acceptance Criteria

1. Playwright installed and configured for headless browser execution (webkit or chromium)
2. Scraper script targets one telco website (recommend O2 or Sky as proven working examples)
3. Script successfully loads target page and waits for dynamic content to render
4. Handles cookie consent modal if present (click accept)
5. Extracts at least 3 SIM-only plan data points: pricing, data allowance, contract term
6. Handles common errors (timeout, element not found) with graceful error logging (fail fast - no retry logic)
7. Outputs scraped data to console as JSON or structured array
8. Script executable via `npm run scrape:poc` command
9. Basic documentation of selectors and scraping logic

## Tasks / Subtasks

- [x] Install Playwright (AC: 1)
  - [x] Install `playwright` package
  - [x] Install browser binaries (chromium)
  - [x] Configure for headless execution
- [x] Create POC scraper script (AC: 2)
  - [x] Choose target telco (O2 selected)
  - [x] Create `src/lib/scraping/collectors/o2.ts`
  - [x] Set up basic Playwright page navigation
- [x] Implement page loading and waiting (AC: 3)
  - [x] Navigate to target URL
  - [x] Wait for dynamic content to render (networkidle)
  - [x] Wait for plan elements to be visible (multiple selector strategies)
- [x] Handle cookie consent (AC: 4)
  - [x] Detect cookie consent modal (multiple selector strategies)
  - [x] Click accept button (site-specific selectors)
  - [x] Wait for modal to close
- [x] Extract plan data (AC: 5)
  - [x] Extract pricing information (regex patterns)
  - [x] Extract data allowance (regex patterns)
  - [x] Extract contract term (regex patterns)
  - [x] Structure data as JSON/array
- [x] Implement error handling (AC: 6)
  - [x] Handle timeout errors
  - [x] Handle element not found errors
  - [x] Add error logging
- [x] Output scraped data (AC: 7)
  - [x] Format as JSON
  - [x] Output to console
  - [x] Verify output format
- [x] Create npm script (AC: 8)
  - [x] Add `scrape:poc` script to `package.json`
  - [x] Script executable via `npm run scrape:poc`
- [x] Document scraper (AC: 9)
  - [x] Document selectors used (README.md in collectors directory)
  - [x] Document scraping logic
  - [x] Document assumptions and limitations

## Dev Notes

### Source Tree
- Scraper location: `src/lib/scraping/collectors/{telco}.ts` (e.g., `o2.ts` or `sky.ts`)
- Main scraping entry point: `src/scripts/scrape.ts` (for future use)
- Playwright uses headless browser execution (webkit or chromium)

### Technical Stack
- Playwright for browser automation
- Headless browser execution
- Site-specific selectors for cookie consent and plan data

### Testing
- Test file location: `tests/integration/scraping/{telco}.test.ts` (to be created)
- Test framework: Jest with mocked Playwright
- Mock network requests to avoid hitting real sites in tests
- Test error handling (fail fast approach)

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-XX | 1.0 | Story extracted from PRD | Architect |
| 2025-11-13 | 1.1 | Story implementation completed | Dev Agent (James) |
| 2025-11-14 | 1.2 | AC6 clarified: Fail fast approach - no retry logic. Error handling focuses on graceful logging for debugging. | PM (John) |

## Dev Agent Record

### Agent Model Used
Auto (Cursor AI)

### Debug Log References
- Playwright installed with Chromium browser
- O2 scraper created with multiple selector strategies for resilience
- Error handling with graceful logging (fail fast approach)
- All linting issues resolved

### Completion Notes List
- Playwright and @playwright/test installed successfully
- Chromium browser binary installed
- O2 scraper created at `src/lib/scraping/collectors/o2.ts` with:
  - Headless browser execution (Chromium)
  - Multiple selector strategies for plan containers and cookie consent
  - Regex-based data extraction for price, data allowance, and contract term
  - Error handling with graceful logging (fail fast - no retry logic)
  - Timeout handling (30s navigation, 15s element wait)
- Test script created at `src/scripts/scrape-poc.ts`
- Added `npm run scrape:poc` script to package.json
- Documentation created at `src/lib/scraping/collectors/README.md`
- All code passes ESLint validation
- **Note**: Scraper uses flexible selector strategies to handle O2's dynamic content. Actual selectors may need adjustment based on O2's current website structure.

### File List
**Created:**
- `src/lib/scraping/collectors/o2.ts` - O2 scraper implementation
- `src/lib/scraping/collectors/README.md` - Scraper documentation
- `src/scripts/scrape-poc.ts` - POC scraping script

**Modified:**
- `package.json` - Added `scrape:poc` script, installed `playwright` and `@playwright/test`

## QA Results

### Review Date: 2025-11-14 (Final Review - Updated for Fail Fast Approach)

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

**Overall: PASS with strong test coverage and solid implementation**

Story 1.3 delivers a functional Playwright-based web scraper with comprehensive test coverage and appropriate fail fast error handling. The implementation demonstrates good understanding of browser automation challenges and provides a solid foundation for multi-source scraping. Product decision to use fail fast approach (no retry logic) is well-suited for POC validation and debugging.

**Strengths:**
- **Strong test coverage**: 20 unit tests covering extraction logic and edge cases
- **Multiple selector strategies**: Resilient to website DOM changes
- **Fail fast error handling**: Graceful error logging
- **Anti-detection measures**: User-agent spoofing, webdriver property removal, cookie injection
- **Export for testing**: `extractPlanFromLocator()` exported for unit testing (good testability design)
- **Flexible data extraction**: Regex patterns handle multiple price/data/contract formats
- **Documentation**: README documenting selectors, logic, assumptions

**Code Quality Highlights:**
- Clean separation of concerns (scraping, cookie handling, data extraction)
- Proper async/await error handling with try-catch
- Structured logging with pino (debug, info, error levels)
- TypeScript interfaces for plan data structure

### Refactoring Performed

No refactoring required. The code follows good practices for web scraping and is well-structured.

### Compliance Check

- **Coding Standards**: ✓ Passes
  - TypeScript with explicit interface (O2Plan)
  - Proper async/await error handling
  - Meaningful variable names (PRODUCT_SELECTOR, O2_URLS)
  - Function documentation with JSDoc-style comments
  - Clean function structure (scrapeO2, handleCookieConsent, extractPlanData, extractPlanFromLocator)

- **Project Structure**: ✓ Passes
  - Scraper in `src/lib/scraping/collectors/o2.ts`
  - Test in co-located `__tests__/` directory
  - Script in `src/scripts/scrape-poc.ts`
  - Documentation in `src/lib/scraping/collectors/README.md`
  - Follows feature-based organization

- **Testing Strategy**: ✓ Exceeds expectations
  - 20 unit tests with vitest
  - Comprehensive coverage of `extractPlanFromLocator()` function
  - Edge cases tested (empty content, errors, Virgin Media filter)
  - Mock-based testing (no real browser required for unit tests)
  - Test organization with describe blocks
  - Real-world format test case included

- **All ACs Met**: ✓ Yes (all 9 acceptance criteria complete)

### Test Architecture Assessment

**Coverage Analysis:**

| Test Category | Test Count | Key Scenarios |
|---------------|-----------|---------------|
| Price extraction | 4 | MONTHLY format, decimal, per month, not found |
| Data allowance | 4 | GB, Unlimited, MB, not found |
| Contract term | 4 | 24mo, 12mo, 1mo, not found |
| Plan name | 3 | First line, title element, default |
| Virgin Media filter | 2 | Skip promo, process normal |
| Edge cases | 3 | Empty content, errors, real-world format |

**Test Quality:**
- ✓ Mock locators for isolated unit testing
- ✓ Regex pattern validation across multiple formats
- ✓ Error handling verification
- ✓ Filter logic tested (Virgin Media promotional cards)
- ✓ Fallback behavior tested (default values when data not found)
- ✓ Real-world content format tested

**Requirements Traceability:**

- **AC1** (Install Playwright): ✓ playwright and @playwright/test in package.json, chromium configured
- **AC2** (Target telco): ✓ O2 selected, multiple URLs for different contract terms
- **AC3** (Load page, wait for content): ✓ Multiple wait strategies (load, timeout, domcontentloaded)
- **AC4** (Cookie consent): ✓ handleCookieConsent() with multiple selector strategies
- **AC5** (Extract 3+ data points): ✓ Price, data allowance, contract term, plus plan name (4 data points)
- **AC6** (Error handling, fail fast): ✓ Try-catch in main scraper, per-URL error handling, graceful logging
- **AC7** (JSON output): ✓ Structured O2Plan interface, console output
- **AC8** (npm script): ✓ `npm run scrape:poc` in package.json
- **AC9** (Documentation): ✓ README.md with selectors, logic, assumptions

### Improvements Checklist

All items assessed and complete:

- [x] Comprehensive test coverage (20 tests for extraction logic)
- [x] Error handling with fail fast approach
- [x] Multiple selector strategies for resilience
- [x] Anti-detection measures (user-agent, webdriver removal, cookies)
- [x] Data extraction with regex patterns and fallbacks

### Issues Identified

None - all acceptance criteria met with fail fast error handling approach.

### Security Review

✓ **PASS** - No security concerns:

- Web scraping is read-only (no data submission)
- No user credentials handled
- User-agent spoofing is legitimate for avoiding bot detection
- No sensitive data exposure in logs

**Note:** Ensure scraped data handling in future stories follows privacy regulations (GDPR, etc.)

### Performance Considerations

⚠️ **CONCERNS** - Scraping performance needs monitoring:

**Current approach:**
- Sequential URL processing (blocks on each URL)
- 5s wait timeout after page load
- 2s waits for cookie consent and button clicks
- Total estimated time: ~25-30s for 3 URLs (1 plan type × 3 contract terms)

**Recommendations for future optimization:**
- Consider parallel URL scraping for multiple contract terms
- Adjust timeouts based on actual page load times
- Implement caching to reduce redundant scrapes
- Monitor actual scrape times and adjust wait strategies

**Current performance acceptable for POC**, but should be optimized in Story 2.2 (data collectors).

### Files Modified During Review

None - code quality is solid and meets all acceptance criteria.

### Gate Status

**Gate: PASS** → `docs/qa/gates/1.3-playwright-scraper-poc.yml`

All acceptance criteria met with fail fast error handling approach.

### Recommended Status

✓ **Ready for Done**

All acceptance criteria satisfied. Implementation demonstrates solid understanding of web scraping with Playwright, proper error handling (fail fast with logging), and comprehensive test coverage (20 unit tests).

